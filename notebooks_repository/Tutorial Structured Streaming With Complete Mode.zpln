{
 "paragraphs": [
  {
   "text": "%md \n## Complete Mode\n\n#### In this mode, every time complete resulting table will be written to sink. Typically used with aggregation queries. In case of aggregations, the output of the result will be keep on changing as and when the new data arrives.",
   "user": "anonymous",
   "dateUpdated": "2020-05-14 20:05:48.410",
   "config": {
    "editorSetting": {
     "language": "text",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "colWidth": 12.0,
    "editorMode": "ace/mode/text",
    "fontSize": 9.0,
    "results": {},
    "enabled": true
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "HTML",
      "data": "<div class=\"markdown-body\">\n<h2>Complete Mode</h2>\n<h4>In this mode, every time complete resulting table will be written to sink. Typically used with aggregation queries. In case of aggregations, the output of the result will be keep on changing as and when the new data arrives.</h4>\n\n</div>"
     }
    ]
   },
   "apps": [],
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1589485763576_-854305522",
   "id": "paragraph_1589480259821_552852928",
   "dateCreated": "2020-05-14 19:49:23.576",
   "dateStarted": "2020-05-15 10:53:17.278",
   "dateFinished": "2020-05-15 10:53:17.295",
   "status": "FINISHED"
  },
  {
   "settings": {
    "params": {},
    "forms": {}
   },
   "apps": [],
   "status": "READY",
   "text": "%md\nimport org.apache.spark.sql.types.{StringType, StructType, TimestampType,IntegerType,FloatType}\n\nprintln(\"Welcome to Spark Structured Streaming Tutorial\")",
   "id": "",
   "config": {}
  },
  {
   "title": "Prepare Data and Schema",
   "text": "val input_dir = \"/data/\" // Initialize data directory to be read from.\nval jsonSchema = new StructType().add(\"time\", TimestampType).add(\"action\", StringType) // Add the schema for data to be read.",
   "user": "anonymous",
   "dateUpdated": "2020-05-14 20:05:48.527",
   "config": {
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "colWidth": 12.0,
    "editorMode": "ace/mode/scala",
    "fontSize": 9.0,
    "title": true,
    "results": {},
    "enabled": true
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "\u001b[1m\u001b[34minput_dir\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = /data/\n\u001b[1m\u001b[34mjsonSchema\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.types.StructType\u001b[0m = StructType(StructField(time,TimestampType,true), StructField(action,StringType,true))\n"
     }
    ]
   },
   "apps": [],
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1589485763586_-1289338863",
   "id": "paragraph_1589312501267_1648295091",
   "dateCreated": "2020-05-14 19:49:23.586",
   "dateStarted": "2020-05-15 10:53:17.382",
   "dateFinished": "2020-05-15 10:53:17.529",
   "status": "FINISHED"
  },
  {
   "title": "Create the Stream reading from files",
   "text": "  val streamingInputDF =\n    spark\n      .readStream // `readStream` instead of `read` for creating streaming DataFrame\n      .schema(jsonSchema) // Set the schema of the JSON data // Treat a sequence of files as a stream by picking one file at a time\n      .json(input_dir) // read from the data directory\n",
   "user": "anonymous",
   "dateUpdated": "2020-05-14 20:05:48.747",
   "config": {
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "colWidth": 12.0,
    "editorMode": "ace/mode/scala",
    "fontSize": 9.0,
    "title": true,
    "results": {},
    "enabled": true
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "\u001b[1m\u001b[34mstreamingInputDF\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [time: timestamp, action: string]\n"
     }
    ]
   },
   "apps": [],
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1589485763586_1898999229",
   "id": "paragraph_1589313021260_1748617835",
   "dateCreated": "2020-05-14 19:49:23.586",
   "dateStarted": "2020-05-15 10:53:17.579",
   "dateFinished": "2020-05-15 10:53:17.742",
   "status": "FINISHED"
  },
  {
   "title": "GroupBy to count the occurrences of every action during a specified window  ",
   "text": "val streamingGroupedDF =\n       streamingInputDF\n        .groupBy(col(\"action\"), window(col(\"time\"), \"30 seconds\")) // GroupBy on action coulmn with  a window size of 30 seconds based on event time of time column\n        .count()\n        ",
   "user": "anonymous",
   "dateUpdated": "2020-05-14 20:05:48.965",
   "config": {
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "colWidth": 12.0,
    "editorMode": "ace/mode/scala",
    "fontSize": 9.0,
    "title": true,
    "results": {},
    "enabled": true
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "\u001b[1m\u001b[34mstreamingGroupedDF\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [action: string, window: struct<start: timestamp, end: timestamp> ... 1 more field]\n"
     }
    ]
   },
   "apps": [],
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1589485763587_-176693876",
   "id": "paragraph_1589484051932_1247379584",
   "dateCreated": "2020-05-14 19:49:23.587",
   "dateStarted": "2020-05-15 10:53:17.784",
   "dateFinished": "2020-05-15 10:53:17.947",
   "status": "FINISHED"
  },
  {
   "title": "Write the Stream",
   "text": "val query =\n    streamingGroupedDF\n    .writeStream // writeSTream to write the output to the sink in streams\n    .outputMode(\"complete\") // Output mode is complete\n    .format(\"memory\") // Sink mode is memory to query on top of the output data in realtime\n    .queryName(\"Streamer\") // Provide a view name to query the data in sql\n    .option(\"truncate\", false)\n    .start()  // Start the streaming data",
   "user": "anonymous",
   "dateUpdated": "2020-05-14 20:07:47.437",
   "config": {
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "colWidth": 12.0,
    "editorMode": "ace/mode/scala",
    "fontSize": 9.0,
    "title": true,
    "results": {},
    "enabled": true
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "ERROR",
    "msg": [
     {
      "type": "TEXT",
      "data": "java.lang.IllegalArgumentException: Cannot start query with name Streamer as a query with that name is already active\n  at org.apache.spark.sql.streaming.StreamingQueryManager$$anonfun$startQuery$1.apply(StreamingQueryManager.scala:332)\n  at org.apache.spark.sql.streaming.StreamingQueryManager$$anonfun$startQuery$1.apply(StreamingQueryManager.scala:330)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.sql.streaming.StreamingQueryManager.startQuery(StreamingQueryManager.scala:330)\n  at org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:267)\n  ... 48 elided\n"
     }
    ]
   },
   "apps": [],
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1589485763587_-890933704",
   "id": "paragraph_1589313016658_1070192101",
   "dateCreated": "2020-05-14 19:49:23.587",
   "dateStarted": "2020-05-15 10:53:17.985",
   "dateFinished": "2020-05-15 10:53:18.274",
   "status": "ERROR"
  },
  {
   "title": "Query the Stream",
   "text": "%sql select * from Streamer ;",
   "user": "anonymous",
   "dateUpdated": "2020-05-14 20:08:04.874",
   "config": {
    "editorSetting": {
     "language": "sql",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "colWidth": 12.0,
    "editorMode": "ace/mode/sql",
    "fontSize": 9.0,
    "title": true,
    "results": {
     "0": {
      "graph": {
       "mode": "table",
       "height": 300.0,
       "optionOpen": false,
       "setting": {
        "table": {
         "tableGridState": {},
         "tableColumnTypeState": {
          "names": {
           "action": "string",
           "window": "string",
           "count": "string"
          },
          "updated": false
         },
         "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
         "tableOptionValue": {
          "useFilter": false,
          "showPagination": false,
          "showAggregationFooter": false
         },
         "updated": false,
         "initialized": false
        }
       },
       "commonSetting": {}
      }
     }
    },
    "enabled": true
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TABLE",
      "data": "action\twindow\tcount\nOpen\t[2016-07-26 08:17:00.0,2016-07-26 08:17:30.0]\t4\nClose\t[2016-07-26 08:17:30.0,2016-07-26 08:18:00.0]\t1\nClose\t[2016-07-26 08:17:00.0,2016-07-26 08:17:30.0]\t1\nOpen\t[2016-07-26 08:15:00.0,2016-07-26 08:15:30.0]\t1\nClose\t[2016-07-26 08:15:30.0,2016-07-26 08:16:00.0]\t2\nClose\t[2016-07-26 08:16:30.0,2016-07-26 08:17:00.0]\t1\nOpen\t[2016-07-26 08:17:30.0,2016-07-26 08:18:00.0]\t4\nOpen\t[2016-07-26 08:16:30.0,2016-07-26 08:17:00.0]\t1\n"
     }
    ]
   },
   "apps": [],
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1589485763587_1144162327",
   "id": "paragraph_1589313028505_294909212",
   "dateCreated": "2020-05-14 19:49:23.588",
   "dateStarted": "2020-05-14 20:08:04.893",
   "dateFinished": "2020-05-14 20:08:04.946",
   "status": "FINISHED"
  },
  {
   "title": "Stop the Stream",
   "text": "\nquery.stop()",
   "user": "anonymous",
   "dateUpdated": "2020-05-14 20:07:34.987",
   "config": {
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "colWidth": 12.0,
    "editorMode": "ace/mode/scala",
    "fontSize": 9.0,
    "title": true,
    "results": {},
    "enabled": true
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "SUCCESS",
    "msg": []
   },
   "apps": [],
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1589485763588_-2137236438",
   "id": "paragraph_1589482499300_-1902897895",
   "dateCreated": "2020-05-14 19:49:23.588",
   "dateStarted": "2020-05-14 20:05:38.163",
   "dateFinished": "2020-05-14 20:05:38.415",
   "status": "READY"
  },
  {
   "user": "anonymous",
   "dateUpdated": "2020-05-14 19:49:23.588",
   "config": {
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "colWidth": 12.0,
    "editorMode": "ace/mode/scala",
    "fontSize": 9.0,
    "results": {},
    "enabled": true
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "apps": [],
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1589485763588_1416115917",
   "id": "paragraph_1589482536169_-904210333",
   "dateCreated": "2020-05-14 19:49:23.588",
   "status": "READY"
  }
 ],
 "name": "Structured Streaming With Complete Mode",
 "id": "2FAKWTK8E",
 "defaultInterpreterGroup": "spark",
 "version": "0.9.0-preview1",
 "noteParams": {},
 "noteForms": {},
 "angularObjects": {},
 "config": {
  "isZeppelinNotebookCronEnable": false
 },
 "info": {
  "isRunning": true
 }
}